{
 "cells": [
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"metadata\": {\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2025-09-20T16:56:09.292695Z\",\n",
    "     \"start_time\": \"2025-09-20T16:56:06.692095Z\"\n",
    "    }\n",
    "   },\n",
    "   \"cell_type\": \"code\",\n",
    "   \"source\": [\n",
    "    \"import torch\\n\",\n",
    "    \"import torch.nn as nn\\n\",\n",
    "    \"from TorchCRF import CRF\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import pickle\\n\",\n",
    "    \"from torch.utils.data import Dataset, DataLoader\\n\",\n",
    "    \"from sklearn.metrics import classification_report\\n\",\n",
    "    \"from collections import Counter\\n\",\n",
    "    \"import ast\\n\",\n",
    "    \"import os\\n\",\n",
    "    \"from tqdm.auto import tqdm\\n\",\n",
    "    \"\\n\",\n",
    "    \"TRAIN_BIO_PATH = \\\"../../data/processed/train_bio.csv\\\"\\n\",\n",
    "    \"VAL_BIO_PATH = \\\"../../data/processed/validation_bio.csv\\\"\\n\",\n",
    "    \"EMBEDDINGS_PATH = \\\"../../data/external/embeddings/ru_en_aligned.pkl\\\"\\n\",\n",
    "    \"MODELS_DIR = \\\"../../models/iteration-1/\\\"\"\n",
    "   ],\n",
    "   \"id\": \"51122954c3d90f50\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": 1\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2025-09-20T16:56:09.308216Z\",\n",
    "     \"start_time\": \"2025-09-20T16:56:09.297718Z\"\n",
    "    }\n",
    "   },\n",
    "   \"cell_type\": \"code\",\n",
    "   \"source\": [\n",
    "    \"device = torch.device(\\\"cuda\\\" if torch.cuda.is_available() else \\\"cpu\\\")\\n\",\n",
    "    \"print(f\\\"Информация: Вычисления будут производиться на устройстве: {device}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"SEED = 42\\n\",\n",
    "    \"torch.manual_seed(SEED)\\n\",\n",
    "    \"np.random.seed(SEED)\\n\",\n",
    "    \"if torch.cuda.is_available():\\n\",\n",
    "    \"    torch.cuda.manual_seed_all(SEED)\\n\",\n",
    "    \"    torch.backends.cudnn.deterministic = True\\n\",\n",
    "    \"    torch.backends.cudnn.benchmark = False\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Информация: Random seed ({SEED}) установлен для обеспечения воспроизводимости.\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\nДиагностика CUDA:\\\")\\n\",\n",
    "    \"print(f\\\"- torch.cuda.is_available(): {torch.cuda.is_available()}\\\")\\n\",\n",
    "    \"print(f\\\"- torch.version.cuda: {getattr(torch.version, 'cuda', None)}\\\")\\n\",\n",
    "    \"try:\\n\",\n",
    "    \"    from torch.backends import cudnn\\n\",\n",
    "    \"    print(f\\\"- cudnn.enabled: {cudnn.enabled}, cudnn.version(): {cudnn.version() if hasattr(cudnn, 'version') else None}\\\")\\n\",\n",
    "    \"except Exception as e:\\n\",\n",
    "    \"    print(f\\\"- Информация по cuDNN недоступна: {e}\\\")\\n\",\n",
    "    \"print(f\\\"- torch.cuda.device_count(): {torch.cuda.device_count()}\\\")\\n\",\n",
    "    \"for idx in range(torch.cuda.device_count()):\\n\",\n",
    "    \"    try:\\n\",\n",
    "    \"        print(f\\\"  * [{idx}] {torch.cuda.get_device_name(idx)}\\\")\\n\",\n",
    "    \"    except Exception as e:\\n\",\n",
    "    \"        print(f\\\"  * [{idx}] ошибка чтения имени устройства: {e}\\\")\\n\"\n",
    "   ],\n",
    "   \"id\": \"bbf6ec690b0523e6\",\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"Информация: Вычисления будут производиться на устройстве: cpu\\n\",\n",
    "      \"Информация: Random seed (42) установлен для обеспечения воспроизводимости.\\n\",\n",
    "      \"\\n\",\n",
    "      \"Диагностика CUDA:\\n\",\n",
    "      \"- torch.cuda.is_available(): False\\n\",\n",
    "      \"- torch.version.cuda: None\\n\",\n",
    "      \"- cudnn.enabled: True, cudnn.version(): None\\n\",\n",
    "      \"- torch.cuda.device_count(): 0\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"execution_count\": 2\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"Гиперпараметры \",\n",
    "   \"id\": \"dc347489880f7b04\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2025-09-20T16:56:09.320658Z\",\n",
    "     \"start_time\": \"2025-09-20T16:56:09.317634Z\"\n",
    "    }\n",
    "   },\n",
    "   \"cell_type\": \"code\",\n",
    "   \"source\": [\n",
    "    \"WORD_EMBEDDING_DIM = 300 \\n\",\n",
    "    \"CHAR_EMBEDDING_DIM = 50  \\n\",\n",
    "    \"CHAR_HIDDEN_DIM = 50      \\n\",\n",
    "    \"\\n\",\n",
    "    \"LSTM_HIDDEN_DIM = 256\\n\",\n",
    "    \"LSTM_NUM_LAYERS = 2 \\n\",\n",
    "    \"\\n\",\n",
    "    \"BATCH_SIZE = 32\\n\",\n",
    "    \"LEARNING_RATE = 1e-3\\n\",\n",
    "    \"NUM_EPOCHS = 10 \\n\",\n",
    "    \"DROPOUT_RATE = 0.5 \"\n",
    "   ],\n",
    "   \"id\": \"a40eca17c0cc021f\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": 3\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"Создание модели\",\n",
    "   \"id\": \"bf9254404624ce99\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2025-09-20T16:56:09.339725Z\",\n",
    "     \"start_time\": \"2025-09-20T16:56:09.333694Z\"\n",
    "    }\n",
    "   },\n",
    "   \"cell_type\": \"code\",\n",
    "   \"source\": [\n",
    "    \"class CharEmbedding(nn.Module):\\n\",\n",
    "    \"    def __init__(self, char_vocab_size, embedding_dim, hidden_dim, dropout_rate=0.25):\\n\",\n",
    "    \"        super(CharEmbedding, self).__init__()\\n\",\n",
    "    \"        self.embedding = nn.Embedding(char_vocab_size, embedding_dim, padding_idx=0)\\n\",\n",
    "    \"        self.lstm = nn.LSTM(\\n\",\n",
    "    \"            input_size=embedding_dim,\\n\",\n",
    "    \"            hidden_size=hidden_dim,\\n\",\n",
    "    \"            num_layers=1,\\n\",\n",
    "    \"            bidirectional=True,\\n\",\n",
    "    \"            batch_first=True\\n\",\n",
    "    \"        )\\n\",\n",
    "    \"        self.dropout = nn.Dropout(dropout_rate)\\n\",\n",
    "    \"        print(\\\"Информация: Модуль CharEmbedding успешно инициализирован.\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"    def forward(self, x):\\n\",\n",
    "    \"        batch_size, seq_len, word_len = x.size()\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        x = x.view(batch_size * seq_len, word_len)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        embedded = self.embedding(x)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        embedded = self.dropout(embedded)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        lstm_out, _ = self.lstm(embedded)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        output = lstm_out.permute(0, 2, 1)\\n\",\n",
    "    \"        output = torch.max(output, 2)[0]\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        output = output.view(batch_size, seq_len, -1)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        return self.dropout(output)\"\n",
    "   ],\n",
    "   \"id\": \"c53e827ffdce5bda\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": 4\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2025-09-20T16:56:09.359227Z\",\n",
    "     \"start_time\": \"2025-09-20T16:56:09.352211Z\"\n",
    "    }\n",
    "   },\n",
    "   \"cell_type\": \"code\",\n",
    "   \"source\": [\n",
    "    \"class BiLSTMCrfForNer(nn.Module):\\n\",\n",
    "    \"    def __init__(self,\\n\",\n",
    "    \"                 word_vocab_size,\\n\",\n",
    "    \"                 word_embedding_dim,\\n\",\n",
    "    \"                 char_vocab_size,\\n\",\n",
    "    \"                 char_embedding_dim,\\n\",\n",
    "    \"                 char_hidden_dim,\\n\",\n",
    "    \"                 lstm_hidden_dim,\\n\",\n",
    "    \"                 num_tags,\\n\",\n",
    "    \"                 dropout_rate=0.33,\\n\",\n",
    "    \"                 padding_idx=0):\\n\",\n",
    "    \"        super(BiLSTMCrfForNer, self).__init__()\\n\",\n",
    "    \"\\n\",\n",
    "    \"        self.word_embedding = nn.Embedding(\\n\",\n",
    "    \"            num_embeddings=word_vocab_size,\\n\",\n",
    "    \"            embedding_dim=word_embedding_dim,\\n\",\n",
    "    \"            padding_idx=padding_idx\\n\",\n",
    "    \"        )\\n\",\n",
    "    \"        self.word_embedding.weight.requires_grad = False\\n\",\n",
    "    \"\\n\",\n",
    "    \"        self.char_embedding = CharEmbedding(\\n\",\n",
    "    \"            char_vocab_size=char_vocab_size,\\n\",\n",
    "    \"            embedding_dim=char_embedding_dim,\\n\",\n",
    "    \"            hidden_dim=char_hidden_dim,\\n\",\n",
    "    \"            dropout_rate=dropout_rate\\n\",\n",
    "    \"        )\\n\",\n",
    "    \"\\n\",\n",
    "    \"        self.embedding_dropout = nn.Dropout(dropout_rate)\\n\",\n",
    "    \"\\n\",\n",
    "    \"        self.lstm = nn.LSTM(\\n\",\n",
    "    \"            input_size=word_embedding_dim + (2 * char_hidden_dim),\\n\",\n",
    "    \"            hidden_size=lstm_hidden_dim,\\n\",\n",
    "    \"            num_layers=2,\\n\",\n",
    "    \"            bidirectional=True,\\n\",\n",
    "    \"            batch_first=True,\\n\",\n",
    "    \"            dropout=dropout_rate if 2 > 1 else 0\\n\",\n",
    "    \"        )\\n\",\n",
    "    \"\\n\",\n",
    "    \"        self.classifier = nn.Linear(2 * lstm_hidden_dim, num_tags)\\n\",\n",
    "    \"\\n\",\n",
    "    \"        self.crf = CRF(num_tags=num_tags, batch_first=True)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        print(\\\"Информация: Основная модель BiLSTMCrfForNer успешно инициализирована.\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"    def forward(self, word_ids, char_ids, mask, tags=None):\\n\",\n",
    "    \"        # word_ids: (batch_size, seq_len)\\n\",\n",
    "    \"        # char_ids: (batch_size, seq_len, word_len)\\n\",\n",
    "    \"        # mask: (batch_size, seq_len)\\n\",\n",
    "    \"        # tags: (batch_size, seq_len)\\n\",\n",
    "    \"\\n\",\n",
    "    \"        word_embeds = self.word_embedding(word_ids)\\n\",\n",
    "    \"        char_embeds = self.char_embedding(char_ids)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        combined_embeds = torch.cat([word_embeds, char_embeds], dim=-1)\\n\",\n",
    "    \"        combined_embeds = self.embedding_dropout(combined_embeds)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        lstm_out, _ = self.lstm(combined_embeds)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        emissions = self.classifier(lstm_out)\\n\",\n",
    "    \"\\n\",\n",
    "    \"        # Гарантируем булев тип маски для совместимости с PyTorch и CRF\\n\",\n",
    "    \"        mask = mask.bool()\\n\",\n",
    "    \"\\n\",\n",
    "    \"        if tags is not None:\\n\",\n",
    "    \"            loss = -self.crf(emissions, tags, mask=mask, reduction='mean')\\n\",\n",
    "    \"            return loss\\n\",\n",
    "    \"        else:\\n\",\n",
    "    \"            decoded_tags = self.crf.decode(emissions, mask=mask)\\n\",\n",
    "    \"            return decoded_tags\"\n",
    "   ],\n",
    "   \"id\": \"1a1edc3e6e787f9e\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": 5\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"Подача данных\",\n",
    "   \"id\": \"2565014e528d16e5\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2025-09-20T16:56:09.384749Z\",\n",
    "     \"start_time\": \"2025-09-20T16:56:09.370303Z\"\n",
    "    }\n",
    "   },\n",
    "   \"cell_type\": \"code\",\n",
    "   \"source\": [\n",
    "    \"class NerDataset(Dataset):\\n\",\n",
    "    \"    def __init__(self, df_path, word2id=None, char2id=None, tag2id=None):\\n\",\n",
    "    \"        self.df = pd.read_csv(df_path, sep=\\\";\\\")\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        self.df['tokens'] = self.df['tokens'].apply(ast.literal_eval)\\n\",\n",
    "    \"        self.df['tags'] = self.df['tags'].apply(ast.literal_eval)\\n\",\n",
    "    \"\\n\",\n",
    "    \"        if word2id is None:\\n\",\n",
    "    \"            self.word2id, self.id2word = self._build_vocab(self.df['tokens'])\\n\",\n",
    "    \"        else:\\n\",\n",
    "    \"            self.word2id, self.id2word = word2id, {v: k for k, v in word2id.items()}\\n\",\n",
    "    \"\\n\",\n",
    "    \"        if char2id is None:\\n\",\n",
    "    \"            all_chars = set(\\\"\\\".join([\\\"\\\".join(tokens) for tokens in self.df['tokens']]))\\n\",\n",
    "    \"            self.char2id, self.id2char = self._build_char_vocab(all_chars)\\n\",\n",
    "    \"        else:\\n\",\n",
    "    \"            self.char2id, self.id2char = char2id, {v: k for k, v in char2id.items()}\\n\",\n",
    "    \"\\n\",\n",
    "    \"        if tag2id is None:\\n\",\n",
    "    \"            # ВАЖНО: строим словарь ТЕГОВ без <UNK>, обязательно добавляем O\\n\",\n",
    "    \"            self.tag2id, self.id2tag = self._build_tag_vocab(self.df['tags'])\\n\",\n",
    "    \"        else:\\n\",\n",
    "    \"            self.tag2id, self.id2tag = tag2id, {v: k for k, v in tag2id.items()}\\n\",\n",
    "    \"            \\n\",\n",
    "    \"        print(f\\\"Информация: Dataset загружен. Размер: {len(self.df)} записей.\\\")\\n\",\n",
    "    \"        print(f\\\"Информация: Размер словаря слов: {len(self.word2id)}\\\")\\n\",\n",
    "    \"        print(f\\\"Информация: Размер словаря символов: {len(self.char2id)}\\\")\\n\",\n",
    "    \"        print(f\\\"Информация: Размер словаря тегов: {len(self.tag2id)}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"    def _build_vocab(self, data):\\n\",\n",
    "    \"        vocab = {\\\"<PAD>\\\": 0, \\\"<UNK>\\\": 1}\\n\",\n",
    "    \"        for sequence in data:\\n\",\n",
    "    \"            for item in sequence:\\n\",\n",
    "    \"                if item not in vocab:\\n\",\n",
    "    \"                    vocab[item] = len(vocab)\\n\",\n",
    "    \"        id2vocab = {v: k for k, v in vocab.items()}\\n\",\n",
    "    \"        return vocab, id2vocab\\n\",\n",
    "    \"\\n\",\n",
    "    \"    def _build_char_vocab(self, chars):\\n\",\n",
    "    \"        vocab = {\\\"<PAD>\\\": 0, \\\"<UNK>\\\": 1}\\n\",\n",
    "    \"        for char in sorted(list(chars)):\\n\",\n",
    "    \"            if char not in vocab:\\n\",\n",
    "    \"                vocab[char] = len(vocab)\\n\",\n",
    "    \"        id2vocab = {v: k for k, v in vocab.items()}\\n\",\n",
    "    \"        return vocab, id2vocab\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # НОВОЕ: билдер словаря для тегов (без <UNK>), с обязательным 'O'\\n\",\n",
    "    \"    def _build_tag_vocab(self, tags_series):\\n\",\n",
    "    \"        tag_vocab = {\\\"<PAD>\\\": 0}\\n\",\n",
    "    \"        # гарантируем наличие 'O'\\n\",\n",
    "    \"        if \\\"O\\\" not in tag_vocab:\\n\",\n",
    "    \"            tag_vocab[\\\"O\\\"] = len(tag_vocab)\\n\",\n",
    "    \"        for seq in tags_series:\\n\",\n",
    "    \"            for tag in seq:\\n\",\n",
    "    \"                if tag not in tag_vocab:\\n\",\n",
    "    \"                    tag_vocab[tag] = len(tag_vocab)\\n\",\n",
    "    \"        id2tag = {v: k for k, v in tag_vocab.items()}\\n\",\n",
    "    \"        return tag_vocab, id2tag\\n\",\n",
    "    \"    # ... existing code ...\\n\",\n",
    "    \"    def __len__(self):\\n\",\n",
    "    \"        return len(self.df)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    def __getitem__(self, idx):\\n\",\n",
    "    \"        row = self.df.iloc[idx]\\n\",\n",
    "    \"        tokens = row['tokens']\\n\",\n",
    "    \"        tags = row['tags']\\n\",\n",
    "    \"\\n\",\n",
    "    \"        word_ids = [self.word2id.get(token, self.word2id[\\\"<UNK>\\\"]) for token in tokens]\\n\",\n",
    "    \"        # ВАЖНО: неизвестные теги (на случай аномалий) отправляем в 'O', а не в <PAD>\\n\",\n",
    "    \"        o_idx = self.tag2id.get(\\\"O\\\", 0)\\n\",\n",
    "    \"        tag_ids = [self.tag2id.get(tag, o_idx) for tag in tags]  # никаких паддингов в середине последовательности\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        char_ids = []\\n\",\n",
    "    \"        for token in tokens:\\n\",\n",
    "    \"            ids = [self.char2id.get(char, self.char2id[\\\"<UNK>\\\"]) for char in token]\\n\",\n",
    "    \"            char_ids.append(ids)\\n\",\n",
    "    \"\\n\",\n",
    "    \"        return {\\\"words\\\": word_ids, \\\"chars\\\": char_ids, \\\"tags\\\": tag_ids}\\n\",\n",
    "    \"\\n\",\n",
    "    \"def collate_fn(batch, word_pad_idx=0, char_pad_idx=0, tag_pad_idx=0):\\n\",\n",
    "    \"    max_seq_len = max(len(item['words']) for item in batch)\\n\",\n",
    "    \"    max_word_len = max(max(len(char_seq) for char_seq in item['chars']) if item['chars'] else 0 for item in batch)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    padded_words, padded_chars, padded_tags, masks = [], [], [], []\\n\",\n",
    "    \"\\n\",\n",
    "    \"    for item in batch:\\n\",\n",
    "    \"        seq_len = len(item['words'])\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        padded_words.append(item['words'] + [word_pad_idx] * (max_seq_len - seq_len))\\n\",\n",
    "    \"        padded_tags.append(item['tags'] + [tag_pad_idx] * (max_seq_len - seq_len))\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        masks.append([1] * seq_len + [0] * (max_seq_len - seq_len))\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        padded_char_seq = []\\n\",\n",
    "    \"        for char_seq in item['chars']:\\n\",\n",
    "    \"            padded_char_seq.append(char_seq + [char_pad_idx] * (max_word_len - len(char_seq)))\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        if seq_len < max_seq_len:\\n\",\n",
    "    \"            for _ in range(max_seq_len - seq_len):\\n\",\n",
    "    \"                padded_char_seq.append([char_pad_idx] * max_word_len)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        padded_chars.append(padded_char_seq)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    return {\\n\",\n",
    "    \"        \\\"words\\\": torch.tensor(padded_words, dtype=torch.long),\\n\",\n",
    "    \"        \\\"chars\\\": torch.tensor(padded_chars, dtype=torch.long),\\n\",\n",
    "    \"        \\\"tags\\\": torch.tensor(padded_tags, dtype=torch.long),\\n\",\n",
    "    \"        \\\"mask\\\": torch.tensor(masks, dtype=torch.bool)\\n\",\n",
    "    \"    }\"\n",
    "   ],\n",
    "   \"id\": \"1c34813e294d9b1b\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": 6\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"Цикл обучения и оценки\",\n",
    "   \"id\": \"646479da5e7ee2c3\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2025-09-20T16:56:09.410704Z\",\n",
    "     \"start_time\": \"2025-09-20T16:56:09.393323Z\"\n",
    "    }\n",
    "   },\n",
    "   \"cell_type\": \"code\",\n",
    "   \"source\": [\n",
    "    \"def calculate_class_weights(tags_series, tag2id):\\n\",\n",
    "    \"    all_tags = [tag for seq in tags_series for tag in seq]\\n\",\n",
    "    \"    tag_counts = Counter(all_tags)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Создаем веса. Используем сглаживание, чтобы избежать деления на ноль.\\n\",\n",
    "    \"    # Более редкие классы получат больший вес.\\n\",\n",
    "    \"    weights = torch.ones(len(tag2id), device=device)\\n\",\n",
    "    \"    for tag, count in tag_counts.items():\\n\",\n",
    "    \"        if tag in tag2id:\\n\",\n",
    "    \"            # Вес обратно пропорционален частоте\\n\",\n",
    "    \"            weights[tag2id[tag]] = 1.0 / (count + 1e-6) \\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Нормализуем веса\\n\",\n",
    "    \"    weights = weights / weights.sum()\\n\",\n",
    "    \"    # Увеличим вес редких классов еще сильнее\\n\",\n",
    "    \"    weights = weights.pow(0.5)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    print(\\\"Информация: Рассчитаны веса для классов:\\\")\\n\",\n",
    "    \"    for tag, i in tag2id.items():\\n\",\n",
    "    \"        print(f\\\"- {tag}: {weights[i]:.4f}\\\")\\n\",\n",
    "    \"        \\n\",\n",
    "    \"    return weights\\n\",\n",
    "    \"\\n\",\n",
    "    \"def train_epoch(model, dataloader, optimizer):\\n\",\n",
    "    \"    model.train()\\n\",\n",
    "    \"    total_loss = 0\\n\",\n",
    "    \"    # Прогресс-бар по батчам\\n\",\n",
    "    \"    pbar = tqdm(dataloader, desc=\\\"Train\\\", leave=False, dynamic_ncols=True)\\n\",\n",
    "    \"    for batch in pbar:\\n\",\n",
    "    \"        # Перенос данных на нужное устройство\\n\",\n",
    "    \"        words = batch['words'].to(device)\\n\",\n",
    "    \"        chars = batch['chars'].to(device)\\n\",\n",
    "    \"        tags = batch['tags'].to(device)\\n\",\n",
    "    \"        mask = batch['mask'].to(device)\\n\",\n",
    "    \"\\n\",\n",
    "    \"        # Обнуление градиентов\\n\",\n",
    "    \"        optimizer.zero_grad()\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Прямой проход и вычисление потерь\\n\",\n",
    "    \"        loss = model(words, chars, mask, tags)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Обратный проход\\n\",\n",
    "    \"        loss.backward()\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Шаг оптимизатора\\n\",\n",
    "    \"        optimizer.step()\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        total_loss += loss.item()\\n\",\n",
    "    \"        # Обновляем подпись прогресс-бара\\n\",\n",
    "    \"        pbar.set_postfix(loss=f\\\"{loss.item():.4f}\\\")\\n\",\n",
    "    \"        \\n\",\n",
    "    \"    return total_loss / len(dataloader)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# --- НОВОЕ: Entity-level оценка BIO ---\\n\",\n",
    "    \"\\n\",\n",
    "    \"def _extract_entities_bio(tags_seq):\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    Превращает список BIO-тегов в множество сущностей вида (type, start, end),\\n\",\n",
    "    \"    где start/end — индексы (включительно) в пределах последовательности.\\n\",\n",
    "    \"    Нормализация BIO: одиночные 'I-X' без валидного 'B-X' считаем как начало новой сущности.\\n\",\n",
    "    \"    Служебные теги ('O', '<PAD>', '<UNK>') игнорируются.\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    entities = set()\\n\",\n",
    "    \"    cur_type = None\\n\",\n",
    "    \"    start = None\\n\",\n",
    "    \"\\n\",\n",
    "    \"    def close_entity(end_idx):\\n\",\n",
    "    \"        nonlocal cur_type, start\\n\",\n",
    "    \"        if cur_type is not None and start is not None:\\n\",\n",
    "    \"            entities.add((cur_type, start, end_idx))\\n\",\n",
    "    \"        cur_type, start = None, None\\n\",\n",
    "    \"\\n\",\n",
    "    \"    for i, tag in enumerate(tags_seq):\\n\",\n",
    "    \"        if tag in (\\\"O\\\", \\\"<PAD>\\\", \\\"<UNK>\\\") or not isinstance(tag, str):\\n\",\n",
    "    \"            # Закрываем текущую сущность\\n\",\n",
    "    \"            if cur_type is not None:\\n\",\n",
    "    \"                close_entity(i - 1)\\n\",\n",
    "    \"            continue\\n\",\n",
    "    \"\\n\",\n",
    "    \"        if tag.startswith(\\\"B-\\\"):\\n\",\n",
    "    \"            # Закрываем предыдущую, открываем новую\\n\",\n",
    "    \"            if cur_type is not None:\\n\",\n",
    "    \"                close_entity(i - 1)\\n\",\n",
    "    \"            cur_type = tag[2:]\\n\",\n",
    "    \"            start = i\\n\",\n",
    "    \"        elif tag.startswith(\\\"I-\\\"):\\n\",\n",
    "    \"            t = tag[2:]\\n\",\n",
    "    \"            if cur_type == t and start is not None:\\n\",\n",
    "    \"                # продолжаем ту же сущность\\n\",\n",
    "    \"                pass\\n\",\n",
    "    \"            else:\\n\",\n",
    "    \"                # нарушение BIO: начинаем новую сущность\\n\",\n",
    "    \"                if cur_type is not None:\\n\",\n",
    "    \"                    close_entity(i - 1)\\n\",\n",
    "    \"                cur_type = t\\n\",\n",
    "    \"                start = i\\n\",\n",
    "    \"        else:\\n\",\n",
    "    \"            # Неверный/неизвестный формат — закрываем текущую\\n\",\n",
    "    \"            if cur_type is not None:\\n\",\n",
    "    \"                close_entity(i - 1)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Закрываем хвост, если открыт\\n\",\n",
    "    \"    if cur_type is not None:\\n\",\n",
    "    \"        close_entity(len(tags_seq) - 1)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    return entities\\n\",\n",
    "    \"\\n\",\n",
    "    \"def _compute_entity_report(all_true_entities, all_pred_entities):\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    На вход — списки множеств сущностей по батчам/предложениям.\\n\",\n",
    "    \"    Возвращает отчёт с precision/recall/f1 per type и micro/macro/weighted averages.\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    # Агрегируем по типам\\n\",\n",
    "    \"    per_type = {}\\n\",\n",
    "    \"    support_per_type = Counter()\\n\",\n",
    "    \"\\n\",\n",
    "    \"    total_tp = total_fp = total_fn = 0\\n\",\n",
    "    \"\\n\",\n",
    "    \"    for true_set, pred_set in zip(all_true_entities, all_pred_entities):\\n\",\n",
    "    \"        # По типам\\n\",\n",
    "    \"        types = set([t for (t, _, _) in true_set]) | set([t for (t, _, _) in pred_set])\\n\",\n",
    "    \"        for t in types:\\n\",\n",
    "    \"            true_t = {e for e in true_set if e[0] == t}\\n\",\n",
    "    \"            pred_t = {e for e in pred_set if e[0] == t}\\n\",\n",
    "    \"            tp = len(true_t & pred_t)\\n\",\n",
    "    \"            fp = len(pred_t - true_t)\\n\",\n",
    "    \"            fn = len(true_t - pred_t)\\n\",\n",
    "    \"\\n\",\n",
    "    \"            if t not in per_type:\\n\",\n",
    "    \"                per_type[t] = {\\\"tp\\\": 0, \\\"fp\\\": 0, \\\"fn\\\": 0}\\n\",\n",
    "    \"            per_type[t][\\\"tp\\\"] += tp\\n\",\n",
    "    \"            per_type[t][\\\"fp\\\"] += fp\\n\",\n",
    "    \"            per_type[t][\\\"fn\\\"] += fn\\n\",\n",
    "    \"            support_per_type[t] += len(true_t)\\n\",\n",
    "    \"\\n\",\n",
    "    \"            total_tp += tp\\n\",\n",
    "    \"            total_fp += fp\\n\",\n",
    "    \"            total_fn += fn\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Формируем метрики\\n\",\n",
    "    \"    report = {}\\n\",\n",
    "    \"    for t, c in per_type.items():\\n\",\n",
    "    \"        tp, fp, fn = c[\\\"tp\\\"], c[\\\"fp\\\"], c[\\\"fn\\\"]\\n\",\n",
    "    \"        prec = tp / (tp + fp) if (tp + fp) > 0 else 0.0\\n\",\n",
    "    \"        rec = tp / (tp + fn) if (tp + fn) > 0 else 0.0\\n\",\n",
    "    \"        f1 = 2 * prec * rec / (prec + rec) if (prec + rec) > 0 else 0.0\\n\",\n",
    "    \"        report[t] = {\\n\",\n",
    "    \"            \\\"precision\\\": prec,\\n\",\n",
    "    \"            \\\"recall\\\": rec,\\n\",\n",
    "    \"            \\\"f1-score\\\": f1,\\n\",\n",
    "    \"            \\\"support\\\": support_per_type[t],\\n\",\n",
    "    \"        }\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Micro\\n\",\n",
    "    \"    micro_prec = total_tp / (total_tp + total_fp) if (total_tp + total_fp) > 0 else 0.0\\n\",\n",
    "    \"    micro_rec = total_tp / (total_tp + total_fn) if (total_tp + total_fn) > 0 else 0.0\\n\",\n",
    "    \"    micro_f1 = 2 * micro_prec * micro_rec / (micro_prec + micro_rec) if (micro_prec + micro_rec) > 0 else 0.0\\n\",\n",
    "    \"    report[\\\"micro avg\\\"] = {\\n\",\n",
    "    \"        \\\"precision\\\": micro_prec,\\n\",\n",
    "    \"        \\\"recall\\\": micro_rec,\\n\",\n",
    "    \"        \\\"f1-score\\\": micro_f1,\\n\",\n",
    "    \"        \\\"support\\\": sum(support_per_type.values()),\\n\",\n",
    "    \"    }\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Macro\\n\",\n",
    "    \"    valid_types = [t for t in report.keys() if t not in (\\\"micro avg\\\", \\\"macro avg\\\", \\\"weighted avg\\\")]\\n\",\n",
    "    \"    if valid_types:\\n\",\n",
    "    \"        macro_prec = sum(report[t][\\\"precision\\\"] for t in valid_types) / len(valid_types)\\n\",\n",
    "    \"        macro_rec = sum(report[t][\\\"recall\\\"] for t in valid_types) / len(valid_types)\\n\",\n",
    "    \"        macro_f1 = sum(report[t][\\\"f1-score\\\"] for t in valid_types) / len(valid_types)\\n\",\n",
    "    \"    else:\\n\",\n",
    "    \"        macro_prec = macro_rec = macro_f1 = 0.0\\n\",\n",
    "    \"    report[\\\"macro avg\\\"] = {\\n\",\n",
    "    \"        \\\"precision\\\": macro_prec,\\n\",\n",
    "    \"        \\\"recall\\\": macro_rec,\\n\",\n",
    "    \"        \\\"f1-score\\\": macro_f1,\\n\",\n",
    "    \"        \\\"support\\\": sum(support_per_type.values()),\\n\",\n",
    "    \"    }\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Weighted\\n\",\n",
    "    \"    total_support = sum(support_per_type.values())\\n\",\n",
    "    \"    if total_support > 0:\\n\",\n",
    "    \"        weighted_prec = sum(report[t][\\\"precision\\\"] * support_per_type[t] for t in valid_types) / total_support\\n\",\n",
    "    \"        weighted_rec = sum(report[t][\\\"recall\\\"] * support_per_type[t] for t in valid_types) / total_support\\n\",\n",
    "    \"        weighted_f1 = sum(report[t][\\\"f1-score\\\"] * support_per_type[t] for t in valid_types) / total_support\\n\",\n",
    "    \"    else:\\n\",\n",
    "    \"        weighted_prec = weighted_rec = weighted_f1 = 0.0\\n\",\n",
    "    \"    report[\\\"weighted avg\\\"] = {\\n\",\n",
    "    \"        \\\"precision\\\": weighted_prec,\\n\",\n",
    "    \"        \\\"recall\\\": weighted_rec,\\n\",\n",
    "    \"        \\\"f1-score\\\": weighted_f1,\\n\",\n",
    "    \"        \\\"support\\\": total_support,\\n\",\n",
    "    \"    }\\n\",\n",
    "    \"\\n\",\n",
    "    \"    return report\\n\",\n",
    "    \"\\n\",\n",
    "    \"def eval_epoch_entities(model, dataloader, id2tag):\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    Entity-level оценка: извлекаем сущности из BIO-последовательностей\\n\",\n",
    "    \"    и считаем метрики по сущностям.\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    model.eval()\\n\",\n",
    "    \"    all_true_entities = []\\n\",\n",
    "    \"    all_pred_entities = []\\n\",\n",
    "    \"\\n\",\n",
    "    \"    with torch.no_grad():\\n\",\n",
    "    \"        for batch in tqdm(dataloader, desc=\\\"Eval\\\", leave=False, dynamic_ncols=True):\\n\",\n",
    "    \"            words = batch['words'].to(device)\\n\",\n",
    "    \"            chars = batch['chars'].to(device)\\n\",\n",
    "    \"            tags = batch['tags'].to(device)\\n\",\n",
    "    \"            mask = batch['mask'].to(device)\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            # Получение предсказаний\\n\",\n",
    "    \"            predictions = model(words, chars, mask)\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            # По каждому предложению вырезаем по фактической длине (по mask)\\n\",\n",
    "    \"            for i in range(len(predictions)):\\n\",\n",
    "    \"                seq_len = mask[i].sum().item()\\n\",\n",
    "    \"                true_ids = tags[i][:seq_len].cpu().tolist()\\n\",\n",
    "    \"                pred_ids = predictions[i][:seq_len]\\n\",\n",
    "    \"\\n\",\n",
    "    \"                true_tags = [id2tag[idx] for idx in true_ids]\\n\",\n",
    "    \"                pred_tags = [id2tag[idx] for idx in pred_ids]\\n\",\n",
    "    \"\\n\",\n",
    "    \"                true_ents = _extract_entities_bio(true_tags)\\n\",\n",
    "    \"                pred_ents = _extract_entities_bio(pred_tags)\\n\",\n",
    "    \"\\n\",\n",
    "    \"                all_true_entities.append(true_ents)\\n\",\n",
    "    \"                all_pred_entities.append(pred_ents)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Готовим финальный отчёт\\n\",\n",
    "    \"    return _compute_entity_report(all_true_entities, all_pred_entities)\"\n",
    "   ],\n",
    "   \"id\": \"c47cb657604d7dd6\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": 7\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"Подготовка эмбеддингов\",\n",
    "   \"id\": \"99163b9c4443e94c\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2025-09-20T16:56:09.423791Z\",\n",
    "     \"start_time\": \"2025-09-20T16:56:09.417921Z\"\n",
    "    }\n",
    "   },\n",
    "   \"cell_type\": \"code\",\n",
    "   \"source\": [\n",
    "    \"def load_and_prepare_embeddings(word2id, filepath, embedding_dim):\\n\",\n",
    "    \"    with open(filepath, 'rb') as f:\\n\",\n",
    "    \"        fasttext_model = pickle.load(f)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    embedding_matrix = np.random.uniform(-0.05, 0.05, (len(word2id), embedding_dim))\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    hits = 0\\n\",\n",
    "    \"    for word, i in word2id.items():\\n\",\n",
    "    \"        if word in fasttext_model:\\n\",\n",
    "    \"            embedding_matrix[i] = fasttext_model[word]\\n\",\n",
    "    \"            hits += 1\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(f\\\"Информация: Найдено {hits} из {len(word2id)} слов в предобученной модели ({hits / len(word2id) * 100:.2f}%).\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    embedding_matrix[word2id[\\\"<PAD>\\\"]] = np.zeros(embedding_dim)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    return torch.tensor(embedding_matrix, dtype=torch.float)\"\n",
    "   ],\n",
    "   \"id\": \"f84fc6823b629e0e\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": 8\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"ОБУЧЕНИЕ\",\n",
    "   \"id\": \"2dee636ed1f16add\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"Загрузка данных\",\n",
    "   \"id\": \"fb7efa016b605e29\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2025-09-20T16:56:27.453878Z\",\n",
    "     \"start_time\": \"2025-09-20T16:56:09.435344Z\"\n",
    "    }\n",
    "   },\n",
    "   \"cell_type\": \"code\",\n",
    "   \"source\": [\n",
    "    \"train_dataset = NerDataset(TRAIN_BIO_PATH)\\n\",\n",
    "    \"\\n\",\n",
    "    \"val_dataset = NerDataset(VAL_BIO_PATH, \\n\",\n",
    "    \"                         word2id=train_dataset.word2id, \\n\",\n",
    "    \"                         char2id=train_dataset.char2id, \\n\",\n",
    "    \"                         tag2id=train_dataset.tag2id)\\n\",\n",
    "    \"\\n\",\n",
    "    \"train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\\n\",\n",
    "    \"val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\nИнформация: Датасеты и даталоадеры успешно созданы.\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"embedding_weights = load_and_prepare_embeddings(train_dataset.word2id, EMBEDDINGS_PATH, WORD_EMBEDDING_DIM)\"\n",
    "   ],\n",
    "   \"id\": \"723c0986ded598b2\",\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"Информация: Dataset загружен. Размер: 23163 записей.\\n\",\n",
    "      \"Информация: Размер словаря слов: 6108\\n\",\n",
    "      \"Информация: Размер словаря символов: 101\\n\",\n",
    "      \"Информация: Размер словаря тегов: 9\\n\",\n",
    "      \"Информация: Dataset загружен. Размер: 4088 записей.\\n\",\n",
    "      \"Информация: Размер словаря слов: 6108\\n\",\n",
    "      \"Информация: Размер словаря символов: 101\\n\",\n",
    "      \"Информация: Размер словаря тегов: 9\\n\",\n",
    "      \"\\n\",\n",
    "      \"Информация: Датасеты и даталоадеры успешно созданы.\\n\",\n",
    "      \"Информация: Найдено 3132 из 6108 слов в предобученной модели (51.28%).\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"execution_count\": 9\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"Инициализация модели\",\n",
    "   \"id\": \"891480b1966f41bb\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2025-09-20T16:56:29.176978Z\",\n",
    "     \"start_time\": \"2025-09-20T16:56:27.620450Z\"\n",
    "    }\n",
    "   },\n",
    "   \"cell_type\": \"code\",\n",
    "   \"source\": [\n",
    "    \"if embedding_weights is not None:\\n\",\n",
    "    \"    model = BiLSTMCrfForNer(\\n\",\n",
    "    \"        word_vocab_size=len(train_dataset.word2id),\\n\",\n",
    "    \"        word_embedding_dim=WORD_EMBEDDING_DIM,\\n\",\n",
    "    \"        char_vocab_size=len(train_dataset.char2id),\\n\",\n",
    "    \"        char_embedding_dim=CHAR_EMBEDDING_DIM,\\n\",\n",
    "    \"        char_hidden_dim=CHAR_HIDDEN_DIM,\\n\",\n",
    "    \"        lstm_hidden_dim=LSTM_HIDDEN_DIM,\\n\",\n",
    "    \"        num_tags=len(train_dataset.tag2id),\\n\",\n",
    "    \"        dropout_rate=DROPOUT_RATE,\\n\",\n",
    "    \"        padding_idx=train_dataset.word2id[\\\"<PAD>\\\"]\\n\",\n",
    "    \"    )\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    model.word_embedding.weight.data.copy_(embedding_weights)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    model.to(device)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    print(\\\"\\\\nИнформация: Модель и оптимизатор инициализированы.\\\")\"\n",
    "   ],\n",
    "   \"id\": \"a6f5830eac67f53a\",\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"Информация: Модуль CharEmbedding успешно инициализирован.\\n\",\n",
    "      \"Информация: Основная модель BiLSTMCrfForNer успешно инициализирована.\\n\",\n",
    "      \"\\n\",\n",
    "      \"Информация: Модель и оптимизатор инициализированы.\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"execution_count\": 10\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"Оценка обучения\",\n",
    "   \"id\": \"a38bab2a8919868f\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"def eval_epoch(model, dataloader, id2tag):\\n\",\n",
    "    \"    model.eval() \\n\",\n",
    "    \"    all_true_tags = []\\n\",\n",
    "    \"    all_pred_tags = []\\n\",\n",
    "    \"\\n\",\n",
    "    \"    with torch.no_grad():\\n\",\n",
    "    \"        for batch in tqdm(dataloader, desc=\\\"Оценка на валидации\\\"):\\n\",\n",
    "    \"            words = batch['words'].to(device)\\n\",\n",
    "    \"            chars = batch['chars'].to(device)\\n\",\n",
    "    \"            tags = batch['tags'].to(device)\\n\",\n",
    "    \"            mask = batch['mask'].to(device)\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            predictions = model(words, chars, mask)\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            for i in range(len(predictions)):\\n\",\n",
    "    \"                seq_len = mask[i].sum().item()\\n\",\n",
    "    \"                \\n\",\n",
    "    \"                true_tags = tags[i][:seq_len].cpu().tolist()\\n\",\n",
    "    \"                pred_tags = predictions[i][:seq_len]\\n\",\n",
    "    \"                \\n\",\n",
    "    \"                all_true_tags.extend([id2tag[tag_id] for tag_id in true_tags])\\n\",\n",
    "    \"                all_pred_tags.extend([id2tag[tag_id] for tag_id in pred_tags])\\n\",\n",
    "    \"\\n\",\n",
    "    \"    labels_to_include = [tag for tag in id2tag.values() if tag not in [\\\"O\\\", \\\"<PAD>\\\", \\\"<UNK>\\\"]]\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    report = classification_report(\\n\",\n",
    "    \"        all_true_tags, \\n\",\n",
    "    \"        all_pred_tags, \\n\",\n",
    "    \"        labels=labels_to_include,\\n\",\n",
    "    \"        output_dict=True, \\n\",\n",
    "    \"        zero_division=0 \\n\",\n",
    "    \"    )\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    return report\"\n",
    "   ],\n",
    "   \"id\": \"2947a69e2bfb17ab\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"Запуск обучения\",\n",
    "   \"id\": \"bd123e707458fe3f\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2025-09-20T17:04:38.984082Z\",\n",
    "     \"start_time\": \"2025-09-20T16:56:29.190580Z\"\n",
    "    }\n",
    "   },\n",
    "   \"cell_type\": \"code\",\n",
    "   \"source\": [\n",
    "    \"best_val_f1 = 0.0\\n\",\n",
    "    \"history = []\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\n--- Начало процесса обучения ---\\\")\\n\",\n",
    "    \"# Прогресс-бар по эпохам\\n\",\n",
    "    \"for epoch in tqdm(range(1, NUM_EPOCHS + 1), desc=\\\"Epochs\\\", unit=\\\"epoch\\\", dynamic_ncols=True):\\n\",\n",
    "    \"    train_loss = train_epoch(model, train_dataloader, optimizer)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # НОВОЕ: entity-level отчёт\\n\",\n",
    "    \"    report = eval_epoch_entities(model, val_dataloader, train_dataset.id2tag)\\n\",\n",
    "    \"    val_f1_macro = report['macro avg']['f1-score']\\n\",\n",
    "    \"    val_precision_macro = report['macro avg']['precision']\\n\",\n",
    "    \"    val_recall_macro = report['macro avg']['recall']\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    history.append({\\n\",\n",
    "    \"        'epoch': epoch,\\n\",\n",
    "    \"        'train_loss': train_loss,\\n\",\n",
    "    \"        'val_f1': val_f1_macro,\\n\",\n",
    "    \"        'val_precision': val_precision_macro,\\n\",\n",
    "    \"        'val_recall': val_recall_macro\\n\",\n",
    "    \"    })\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    clear_output(wait=True)\\n\",\n",
    "    \"    print(f\\\"--- Эпоха {epoch}/{NUM_EPOCHS} --- (Длительность: {epoch_duration:.2f} сек)\\\")\\n\",\n",
    "    \"    print(f\\\"  Потери на обучении (Train Loss): {train_loss:.4f}\\\")\\n\",\n",
    "    \"    print(f\\\"  F1-macro (entity-level) на валидации: {val_f1_macro:.4f}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"    print(\\\"  Детальный отчёт по сущностям:\\\")\\n\",\n",
    "    \"    # Выводим только реальные типы (без агрегатов)\\n\",\n",
    "    \"    for tag, metrics in report.items():\\n\",\n",
    "    \"        if isinstance(metrics, dict) and tag not in {\\\"micro avg\\\", \\\"macro avg\\\", \\\"weighted avg\\\"}:\\n\",\n",
    "    \"            print(f\\\"    - {tag:<10}: F1={metrics['f1-score']:.4f}, Precision={metrics['precision']:.4f}, Recall={metrics['recall']:.4f}, Support={metrics['support']}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"    print(\\\"  Агрегаты:\\\")\\n\",\n",
    "    \"    for agg in (\\\"micro avg\\\", \\\"macro avg\\\", \\\"weighted avg\\\"):\\n\",\n",
    "    \"        m = report[agg]\\n\",\n",
    "    \"        print(f\\\"    - {agg:<12}: F1={m['f1-score']:.4f}, Precision={m['precision']:.4f}, Recall={m['recall']:.4f}, Support={m['support']}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"    if val_f1_macro > best_val_f1:\\n\",\n",
    "    \"        best_val_f1 = val_f1_macro\\n\",\n",
    "    \"        best_model_state = model.state_dict().copy()\\n\",\n",
    "    \"        print(f\\\"  Новый лучший результат! Модель сохранена (F1-macro entity-level: {best_val_f1:.4f}).\\\")\\n\",\n",
    "    \"        os.makedirs(MODELS_DIR, exist_ok=True)\\n\",\n",
    "    \"        torch.save(best_model_state, os.path.join(MODELS_DIR, \\\"bilstm_v1_best.pth\\\"))\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\n--- Обучение завершено ---\\\")\\n\",\n",
    "    \"print(f\\\"Лучший F1-macro на валидации: {best_val_f1:.4f}\\\")\"\n",
    "   ],\n",
    "   \"id\": \"ee3d1f8bda91b5dc\",\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"\\n\",\n",
    "      \"--- Начало процесса обучения ---\\n\"\n",
    "     ]\n",
    "    },\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"Epochs:   0%|          | 0/10 [00:00<?, ?epoch/s]\"\n",
    "      ],\n",
    "      \"application/vnd.jupyter.widget-view+json\": {\n",
    "       \"version_major\": 2,\n",
    "       \"version_minor\": 0,\n",
    "       \"model_id\": \"a080e771aef64b3fb9b326b5a7b5319f\"\n",
    "      }\n",
    "     },\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"display_data\"\n",
    "    },\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"Train:   0%|          | 0/724 [00:00<?, ?it/s]\"\n",
    "      ],\n",
    "      \"application/vnd.jupyter.widget-view+json\": {\n",
    "       \"version_major\": 2,\n",
    "       \"version_minor\": 0,\n",
    "       \"model_id\": \"35e959d576e44877a0b0a1b3f705e192\"\n",
    "      }\n",
    "     },\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"display_data\"\n",
    "    },\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"Eval:   0%|          | 0/128 [00:00<?, ?it/s]\"\n",
    "      ],\n",
    "      \"application/vnd.jupyter.widget-view+json\": {\n",
    "       \"version_major\": 2,\n",
    "       \"version_minor\": 0,\n",
    "       \"model_id\": \"38683f68f1374bdaa6f4167dd7114247\"\n",
    "      }\n",
    "     },\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"display_data\"\n",
    "    },\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"\\n\",\n",
    "      \"Эпоха 1/10:\\n\",\n",
    "      \"  Потери на обучении (Train Loss): 1.7776\\n\",\n",
    "      \"  F1-macro (entity-level) на валидации: 0.4001\\n\",\n",
    "      \"  Детальный отчёт по сущностям:\\n\",\n",
    "      \"    - TYPE      : F1=0.9239, Precision=0.8801, Recall=0.9723, Support=4372\\n\",\n",
    "      \"    - BRAND     : F1=0.6765, Precision=0.8115, Recall=0.5801, Support=1143\\n\",\n",
    "      \"    - VOLUME    : F1=0.0000, Precision=0.0000, Recall=0.0000, Support=17\\n\",\n",
    "      \"    - PERCENT   : F1=0.0000, Precision=0.0000, Recall=0.0000, Support=1\\n\",\n",
    "      \"  Агрегаты:\\n\",\n",
    "      \"    - micro avg   : F1=0.8791, Precision=0.8702, Recall=0.8881, Support=5533\\n\",\n",
    "      \"    - macro avg   : F1=0.4001, Precision=0.4229, Recall=0.3881, Support=5533\\n\",\n",
    "      \"    - weighted avg: F1=0.8698, Precision=0.8631, Recall=0.8881, Support=5533\\n\",\n",
    "      \"  Новый лучший результат! Модель сохранена (F1-macro entity-level: 0.4001).\\n\"\n",
    "     ]\n",
    "    },\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"Train:   0%|          | 0/724 [00:00<?, ?it/s]\"\n",
    "      ],\n",
    "      \"application/vnd.jupyter.widget-view+json\": {\n",
    "       \"version_major\": 2,\n",
    "       \"version_minor\": 0,\n",
    "       \"model_id\": \"79a6417dfa2643e58a89f3f29820b16c\"\n",
    "      }\n",
    "     },\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"display_data\"\n",
    "    },\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"Eval:   0%|          | 0/128 [00:00<?, ?it/s]\"\n",
    "      ],\n",
    "      \"application/vnd.jupyter.widget-view+json\": {\n",
    "       \"version_major\": 2,\n",
    "       \"version_minor\": 0,\n",
    "       \"model_id\": \"23b073f78f5d4d4498024fffe3f0c908\"\n",
    "      }\n",
    "     },\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"display_data\"\n",
    "    },\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"\\n\",\n",
    "      \"Эпоха 2/10:\\n\",\n",
    "      \"  Потери на обучении (Train Loss): 0.9985\\n\",\n",
    "      \"  F1-macro (entity-level) на валидации: 0.4027\\n\",\n",
    "      \"  Детальный отчёт по сущностям:\\n\",\n",
    "      \"    - TYPE      : F1=0.9264, Precision=0.8800, Recall=0.9780, Support=4372\\n\",\n",
    "      \"    - BRAND     : F1=0.6842, Precision=0.8607, Recall=0.5678, Support=1143\\n\",\n",
    "      \"    - VOLUME    : F1=0.0000, Precision=0.0000, Recall=0.0000, Support=17\\n\",\n",
    "      \"    - PERCENT   : F1=0.0000, Precision=0.0000, Recall=0.0000, Support=1\\n\",\n",
    "      \"  Агрегаты:\\n\",\n",
    "      \"    - micro avg   : F1=0.8837, Precision=0.8774, Recall=0.8901, Support=5533\\n\",\n",
    "      \"    - macro avg   : F1=0.4027, Precision=0.4352, Recall=0.3865, Support=5533\\n\",\n",
    "      \"    - weighted avg: F1=0.8734, Precision=0.8732, Recall=0.8901, Support=5533\\n\",\n",
    "      \"  Новый лучший результат! Модель сохранена (F1-macro entity-level: 0.4027).\\n\"\n",
    "     ]\n",
    "    },\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"Train:   0%|          | 0/724 [00:00<?, ?it/s]\"\n",
    "      ],\n",
    "      \"application/vnd.jupyter.widget-view+json\": {\n",
    "       \"version_major\": 2,\n",
    "       \"version_minor\": 0,\n",
    "       \"model_id\": \"8e5d0c3f726c486b853e735fddf7f940\"\n",
    "      }\n",
    "     },\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"display_data\"\n",
    "    },\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"Eval:   0%|          | 0/128 [00:00<?, ?it/s]\"\n",
    "      ],\n",
    "      \"application/vnd.jupyter.widget-view+json\": {\n",
    "       \"version_major\": 2,\n",
    "       \"version_minor\": 0,\n",
    "       \"model_id\": \"32ecdbda894b4bb0a24e10b094f6a0c1\"\n",
    "      }\n",
    "     },\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"display_data\"\n",
    "    },\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"\\n\",\n",
    "      \"Эпоха 3/10:\\n\",\n",
    "      \"  Потери на обучении (Train Loss): 0.7785\\n\",\n",
    "      \"  F1-macro (entity-level) на валидации: 0.4178\\n\",\n",
    "      \"  Детальный отчёт по сущностям:\\n\",\n",
    "      \"    - TYPE      : F1=0.9302, Precision=0.9056, Recall=0.9563, Support=4372\\n\",\n",
    "      \"    - BRAND     : F1=0.7408, Precision=0.7669, Recall=0.7165, Support=1143\\n\",\n",
    "      \"    - VOLUME    : F1=0.0000, Precision=0.0000, Recall=0.0000, Support=17\\n\",\n",
    "      \"    - PERCENT   : F1=0.0000, Precision=0.0000, Recall=0.0000, Support=1\\n\",\n",
    "      \"  Агрегаты:\\n\",\n",
    "      \"    - micro avg   : F1=0.8914, Precision=0.8795, Recall=0.9037, Support=5533\\n\",\n",
    "      \"    - macro avg   : F1=0.4178, Precision=0.4181, Recall=0.4182, Support=5533\\n\",\n",
    "      \"    - weighted avg: F1=0.8881, Precision=0.8740, Recall=0.9037, Support=5533\\n\",\n",
    "      \"  Новый лучший результат! Модель сохранена (F1-macro entity-level: 0.4178).\\n\"\n",
    "     ]\n",
    "    },\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"Train:   0%|          | 0/724 [00:00<?, ?it/s]\"\n",
    "      ],\n",
    "      \"application/vnd.jupyter.widget-view+json\": {\n",
    "       \"version_major\": 2,\n",
    "       \"version_minor\": 0,\n",
    "       \"model_id\": \"e69b5a2862ec4beeaf85d777bf0c8d2f\"\n",
    "      }\n",
    "     },\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"display_data\"\n",
    "    },\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"Eval:   0%|          | 0/128 [00:00<?, ?it/s]\"\n",
    "      ],\n",
    "      \"application/vnd.jupyter.widget-view+json\": {\n",
    "       \"version_major\": 2,\n",
    "       \"version_minor\": 0,\n",
    "       \"model_id\": \"82ecb71c5fde4c3793744a8d4db4e8ee\"\n",
    "      }\n",
    "     },\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"display_data\"\n",
    "    },\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"\\n\",\n",
    "      \"Эпоха 4/10:\\n\",\n",
    "      \"  Потери на обучении (Train Loss): 0.6605\\n\",\n",
    "      \"  F1-macro (entity-level) на валидации: 0.4863\\n\",\n",
    "      \"  Детальный отчёт по сущностям:\\n\",\n",
    "      \"    - TYPE      : F1=0.9313, Precision=0.8933, Recall=0.9728, Support=4372\\n\",\n",
    "      \"    - BRAND     : F1=0.7412, Precision=0.8213, Recall=0.6754, Support=1143\\n\",\n",
    "      \"    - VOLUME    : F1=0.2727, Precision=0.6000, Recall=0.1765, Support=17\\n\",\n",
    "      \"    - PERCENT   : F1=0.0000, Precision=0.0000, Recall=0.0000, Support=1\\n\",\n",
    "      \"  Агрегаты:\\n\",\n",
    "      \"    - micro avg   : F1=0.8946, Precision=0.8809, Recall=0.9087, Support=5533\\n\",\n",
    "      \"    - macro avg   : F1=0.4863, Precision=0.5786, Recall=0.4562, Support=5533\\n\",\n",
    "      \"    - weighted avg: F1=0.8899, Precision=0.8774, Recall=0.9087, Support=5533\\n\",\n",
    "      \"  Новый лучший результат! Модель сохранена (F1-macro entity-level: 0.4863).\\n\"\n",
    "     ]\n",
    "    },\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"Train:   0%|          | 0/724 [00:00<?, ?it/s]\"\n",
    "      ],\n",
    "      \"application/vnd.jupyter.widget-view+json\": {\n",
    "       \"version_major\": 2,\n",
    "       \"version_minor\": 0,\n",
    "       \"model_id\": \"f6d6a547c23d464dbcb255c5d45c0d82\"\n",
    "      }\n",
    "     },\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"display_data\"\n",
    "    },\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"Eval:   0%|          | 0/128 [00:00<?, ?it/s]\"\n",
    "      ],\n",
    "      \"application/vnd.jupyter.widget-view+json\": {\n",
    "       \"version_major\": 2,\n",
    "       \"version_minor\": 0,\n",
    "       \"model_id\": \"8955def1d670435fba6da38727576299\"\n",
    "      }\n",
    "     },\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"display_data\"\n",
    "    },\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"\\n\",\n",
    "      \"Эпоха 5/10:\\n\",\n",
    "      \"  Потери на обучении (Train Loss): 0.5903\\n\",\n",
    "      \"  F1-macro (entity-level) на валидации: 0.5277\\n\",\n",
    "      \"  Детальный отчёт по сущностям:\\n\",\n",
    "      \"    - TYPE      : F1=0.9373, Precision=0.9017, Recall=0.9758, Support=4372\\n\",\n",
    "      \"    - BRAND     : F1=0.7598, Precision=0.8529, Recall=0.6850, Support=1143\\n\",\n",
    "      \"    - VOLUME    : F1=0.4138, Precision=0.5000, Recall=0.3529, Support=17\\n\",\n",
    "      \"    - PERCENT   : F1=0.0000, Precision=0.0000, Recall=0.0000, Support=1\\n\",\n",
    "      \"  Агрегаты:\\n\",\n",
    "      \"    - micro avg   : F1=0.9032, Precision=0.8930, Recall=0.9136, Support=5533\\n\",\n",
    "      \"    - macro avg   : F1=0.5277, Precision=0.5637, Recall=0.5034, Support=5533\\n\",\n",
    "      \"    - weighted avg: F1=0.8988, Precision=0.8902, Recall=0.9136, Support=5533\\n\",\n",
    "      \"  Новый лучший результат! Модель сохранена (F1-macro entity-level: 0.5277).\\n\"\n",
    "     ]\n",
    "    },\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"Train:   0%|          | 0/724 [00:00<?, ?it/s]\"\n",
    "      ],\n",
    "      \"application/vnd.jupyter.widget-view+json\": {\n",
    "       \"version_major\": 2,\n",
    "       \"version_minor\": 0,\n",
    "       \"model_id\": \"73c6620edf54486a815d6e5e244e2b94\"\n",
    "      }\n",
    "     },\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"display_data\"\n",
    "    },\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"Eval:   0%|          | 0/128 [00:00<?, ?it/s]\"\n",
    "      ],\n",
    "      \"application/vnd.jupyter.widget-view+json\": {\n",
    "       \"version_major\": 2,\n",
    "       \"version_minor\": 0,\n",
    "       \"model_id\": \"726413d2aa70433c86180d576783d5d6\"\n",
    "      }\n",
    "     },\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"display_data\"\n",
    "    },\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"\\n\",\n",
    "      \"Эпоха 6/10:\\n\",\n",
    "      \"  Потери на обучении (Train Loss): 0.5357\\n\",\n",
    "      \"  F1-macro (entity-level) на валидации: 0.5221\\n\",\n",
    "      \"  Детальный отчёт по сущностям:\\n\",\n",
    "      \"    - TYPE      : F1=0.9362, Precision=0.8978, Recall=0.9780, Support=4372\\n\",\n",
    "      \"    - BRAND     : F1=0.7524, Precision=0.8833, Recall=0.6553, Support=1143\\n\",\n",
    "      \"    - PERCENT   : F1=0.0800, Precision=0.0417, Recall=1.0000, Support=1\\n\",\n",
    "      \"    - VOLUME    : F1=0.3200, Precision=0.5000, Recall=0.2353, Support=17\\n\",\n",
    "      \"  Агрегаты:\\n\",\n",
    "      \"    - micro avg   : F1=0.9001, Precision=0.8914, Recall=0.9091, Support=5533\\n\",\n",
    "      \"    - macro avg   : F1=0.5221, Precision=0.5807, Recall=0.7172, Support=5533\\n\",\n",
    "      \"    - weighted avg: F1=0.8962, Precision=0.8934, Recall=0.9091, Support=5533\\n\"\n",
    "     ]\n",
    "    },\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"Train:   0%|          | 0/724 [00:00<?, ?it/s]\"\n",
    "      ],\n",
    "      \"application/vnd.jupyter.widget-view+json\": {\n",
    "       \"version_major\": 2,\n",
    "       \"version_minor\": 0,\n",
    "       \"model_id\": \"81ec1c83ea824d1f987958be759ae6e9\"\n",
    "      }\n",
    "     },\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"display_data\"\n",
    "    },\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"Eval:   0%|          | 0/128 [00:00<?, ?it/s]\"\n",
    "      ],\n",
    "      \"application/vnd.jupyter.widget-view+json\": {\n",
    "       \"version_major\": 2,\n",
    "       \"version_minor\": 0,\n",
    "       \"model_id\": \"a80a7b9674114312a13961f7ed2efbac\"\n",
    "      }\n",
    "     },\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"display_data\"\n",
    "    },\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"\\n\",\n",
    "      \"Эпоха 7/10:\\n\",\n",
    "      \"  Потери на обучении (Train Loss): 0.5003\\n\",\n",
    "      \"  F1-macro (entity-level) на валидации: 0.5908\\n\",\n",
    "      \"  Детальный отчёт по сущностям:\\n\",\n",
    "      \"    - TYPE      : F1=0.9413, Precision=0.9110, Recall=0.9737, Support=4372\\n\",\n",
    "      \"    - BRAND     : F1=0.7876, Precision=0.8666, Recall=0.7218, Support=1143\\n\",\n",
    "      \"    - VOLUME    : F1=0.6341, Precision=0.5417, Recall=0.7647, Support=17\\n\",\n",
    "      \"    - PERCENT   : F1=0.0000, Precision=0.0000, Recall=0.0000, Support=1\\n\",\n",
    "      \"  Агрегаты:\\n\",\n",
    "      \"    - micro avg   : F1=0.9110, Precision=0.9015, Recall=0.9208, Support=5533\\n\",\n",
    "      \"    - macro avg   : F1=0.5908, Precision=0.5798, Recall=0.6150, Support=5533\\n\",\n",
    "      \"    - weighted avg: F1=0.9084, Precision=0.9005, Recall=0.9208, Support=5533\\n\",\n",
    "      \"  Новый лучший результат! Модель сохранена (F1-macro entity-level: 0.5908).\\n\"\n",
    "     ]\n",
    "    },\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"Train:   0%|          | 0/724 [00:00<?, ?it/s]\"\n",
    "      ],\n",
    "      \"application/vnd.jupyter.widget-view+json\": {\n",
    "       \"version_major\": 2,\n",
    "       \"version_minor\": 0,\n",
    "       \"model_id\": \"f5f8c800b81b491d9b3e9e534ec585ec\"\n",
    "      }\n",
    "     },\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"display_data\"\n",
    "    },\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"Eval:   0%|          | 0/128 [00:00<?, ?it/s]\"\n",
    "      ],\n",
    "      \"application/vnd.jupyter.widget-view+json\": {\n",
    "       \"version_major\": 2,\n",
    "       \"version_minor\": 0,\n",
    "       \"model_id\": \"7cde2f74232d479e9d354f000508cfa1\"\n",
    "      }\n",
    "     },\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"display_data\"\n",
    "    },\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"\\n\",\n",
    "      \"Эпоха 8/10:\\n\",\n",
    "      \"  Потери на обучении (Train Loss): 0.4664\\n\",\n",
    "      \"  F1-macro (entity-level) на валидации: 0.6200\\n\",\n",
    "      \"  Детальный отчёт по сущностям:\\n\",\n",
    "      \"    - TYPE      : F1=0.9430, Precision=0.9156, Recall=0.9721, Support=4372\\n\",\n",
    "      \"    - BRAND     : F1=0.7962, Precision=0.8786, Recall=0.7279, Support=1143\\n\",\n",
    "      \"    - VOLUME    : F1=0.7407, Precision=1.0000, Recall=0.5882, Support=17\\n\",\n",
    "      \"    - PERCENT   : F1=0.0000, Precision=0.0000, Recall=0.0000, Support=1\\n\",\n",
    "      \"  Агрегаты:\\n\",\n",
    "      \"    - micro avg   : F1=0.9148, Precision=0.9094, Recall=0.9203, Support=5533\\n\",\n",
    "      \"    - macro avg   : F1=0.6200, Precision=0.6985, Recall=0.5721, Support=5533\\n\",\n",
    "      \"    - weighted avg: F1=0.9119, Precision=0.9080, Recall=0.9203, Support=5533\\n\",\n",
    "      \"  Новый лучший результат! Модель сохранена (F1-macro entity-level: 0.6200).\\n\"\n",
    "     ]\n",
    "    },\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"Train:   0%|          | 0/724 [00:00<?, ?it/s]\"\n",
    "      ],\n",
    "      \"application/vnd.jupyter.widget-view+json\": {\n",
    "       \"version_major\": 2,\n",
    "       \"version_minor\": 0,\n",
    "       \"model_id\": \"8e108f465f6247e59d380644412b85b5\"\n",
    "      }\n",
    "     },\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"display_data\"\n",
    "    },\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"Eval:   0%|          | 0/128 [00:00<?, ?it/s]\"\n",
    "      ],\n",
    "      \"application/vnd.jupyter.widget-view+json\": {\n",
    "       \"version_major\": 2,\n",
    "       \"version_minor\": 0,\n",
    "       \"model_id\": \"8aaf000b2e754c0c8cac35789ee05716\"\n",
    "      }\n",
    "     },\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"display_data\"\n",
    "    },\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"\\n\",\n",
    "      \"Эпоха 9/10:\\n\",\n",
    "      \"  Потери на обучении (Train Loss): 0.4369\\n\",\n",
    "      \"  F1-macro (entity-level) на валидации: 0.5385\\n\",\n",
    "      \"  Детальный отчёт по сущностям:\\n\",\n",
    "      \"    - TYPE      : F1=0.9477, Precision=0.9240, Recall=0.9728, Support=4372\\n\",\n",
    "      \"    - BRAND     : F1=0.8252, Precision=0.8777, Recall=0.7787, Support=1143\\n\",\n",
    "      \"    - VOLUME    : F1=0.3810, Precision=1.0000, Recall=0.2353, Support=17\\n\",\n",
    "      \"    - PERCENT   : F1=0.0000, Precision=0.0000, Recall=0.0000, Support=1\\n\",\n",
    "      \"  Агрегаты:\\n\",\n",
    "      \"    - micro avg   : F1=0.9227, Precision=0.9153, Recall=0.9302, Support=5533\\n\",\n",
    "      \"    - macro avg   : F1=0.5385, Precision=0.7004, Recall=0.4967, Support=5533\\n\",\n",
    "      \"    - weighted avg: F1=0.9205, Precision=0.9145, Recall=0.9302, Support=5533\\n\"\n",
    "     ]\n",
    "    },\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"Train:   0%|          | 0/724 [00:00<?, ?it/s]\"\n",
    "      ],\n",
    "      \"application/vnd.jupyter.widget-view+json\": {\n",
    "       \"version_major\": 2,\n",
    "       \"version_minor\": 0,\n",
    "       \"model_id\": \"f33d0110281c461b86e08258fd008162\"\n",
    "      }\n",
    "     },\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"display_data\"\n",
    "    },\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"Eval:   0%|          | 0/128 [00:00<?, ?it/s]\"\n",
    "      ],\n",
    "      \"application/vnd.jupyter.widget-view+json\": {\n",
    "       \"version_major\": 2,\n",
    "       \"version_minor\": 0,\n",
    "       \"model_id\": \"838d9617935a4d2bb8b182eebe4079fc\"\n",
    "      }\n",
    "     },\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"display_data\"\n",
    "    },\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"\\n\",\n",
    "      \"Эпоха 10/10:\\n\",\n",
    "      \"  Потери на обучении (Train Loss): 0.4117\\n\",\n",
    "      \"  F1-macro (entity-level) на валидации: 0.5319\\n\",\n",
    "      \"  Детальный отчёт по сущностям:\\n\",\n",
    "      \"    - TYPE      : F1=0.9500, Precision=0.9309, Recall=0.9700, Support=4372\\n\",\n",
    "      \"    - BRAND     : F1=0.8329, Precision=0.8418, Recall=0.8241, Support=1143\\n\",\n",
    "      \"    - VOLUME    : F1=0.3448, Precision=0.4167, Recall=0.2941, Support=17\\n\",\n",
    "      \"    - PERCENT   : F1=0.0000, Precision=0.0000, Recall=0.0000, Support=1\\n\",\n",
    "      \"  Агрегаты:\\n\",\n",
    "      \"    - micro avg   : F1=0.9240, Precision=0.9107, Recall=0.9376, Support=5533\\n\",\n",
    "      \"    - macro avg   : F1=0.5319, Precision=0.5473, Recall=0.5221, Support=5533\\n\",\n",
    "      \"    - weighted avg: F1=0.9238, Precision=0.9107, Recall=0.9376, Support=5533\\n\",\n",
    "      \"\\n\",\n",
    "      \"--- Обучение завершено ---\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"execution_count\": 11\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"Сохранение результатов\",\n",
    "   \"id\": \"9aed5e46fdf29dce\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2025-09-20T17:04:39.077603Z\",\n",
    "     \"start_time\": \"2025-09-20T17:04:39.044310Z\"\n",
    "    }\n",
    "   },\n",
    "   \"cell_type\": \"code\",\n",
    "   \"source\": [\n",
    "    \"artefacts = {\\n\",\n",
    "    \"    \\\"word2id\\\": train_dataset.word2id,\\n\",\n",
    "    \"    \\\"char2id\\\": train_dataset.char2id,\\n\",\n",
    "    \"    \\\"tag2id\\\": train_dataset.tag2id,\\n\",\n",
    "    \"    \\\"id2tag\\\": train_dataset.id2tag\\n\",\n",
    "    \"}\\n\",\n",
    "    \"\\n\",\n",
    "    \"with open(ARTEFACTS_PATH, \\\"wb\\\") as f:\\n\",\n",
    "    \"    pickle.dump(artefacts, f)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Информация: Словари для инференса (артефакты) успешно сохранены в: {ARTEFACTS_PATH}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"history_df = pd.DataFrame(history)\\n\",\n",
    "    \"\\n\",\n",
    "    \"sns.set_style(\\\"whitegrid\\\")\\n\",\n",
    "    \"plt.rcParams['figure.figsize'] = (16, 6)\\n\",\n",
    "    \"\\n\",\n",
    "    \"fig, (ax1, ax2) = plt.subplots(1, 2)\\n\",\n",
    "    \"\\n\",\n",
    "    \"ax1.plot(history_df['epoch'], history_df['train_loss'], label='Потери на обучении', color='b', marker='o')\\n\",\n",
    "    \"ax1.set_title('Динамика потерь на обучении по эпохам', fontsize=14)\\n\",\n",
    "    \"ax1.set_xlabel('Эпоха', fontsize=12)\\n\",\n",
    "    \"ax1.set_ylabel('Значение Loss', fontsize=12)\\n\",\n",
    "    \"ax1.legend()\\n\",\n",
    "    \"ax1.xaxis.set_major_locator(plt.MaxNLocator(integer=True)) \\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"ax2.plot(history_df['epoch'], history_df['val_f1'], label='F1-macro', color='g', marker='o')\\n\",\n",
    "    \"ax2.plot(history_df['epoch'], history_df['val_precision'], label='Precision-macro', color='r', marker='s', linestyle='--')\\n\",\n",
    "    \"ax2.plot(history_df['epoch'], history_df['val_recall'], label='Recall-macro', color='orange', marker='^', linestyle='--')\\n\",\n",
    "    \"ax2.set_title('Динамика метрик на валидации по эпохам', fontsize=14)\\n\",\n",
    "    \"ax2.set_xlabel('Эпоха', fontsize=12)\\n\",\n",
    "    \"ax2.set_ylabel('Значение метрики', fontsize=12)\\n\",\n",
    "    \"ax2.legend()\\n\",\n",
    "    \"ax2.xaxis.set_major_locator(plt.MaxNLocator(integer=True))\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.savefig(CHART_PATH)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Информация: Графики процесса обучения сохранены в: {CHART_PATH}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.show()\"\n",
    "   ],\n",
    "   \"id\": \"468d340b8b26261\"\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 2\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython2\",\n",
    "   \"version\": \"2.7.6\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 5\n",
    "}\n"
   ],
   "id": "953c9d8caf70f645"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
